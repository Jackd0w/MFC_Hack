# local package
-e .
llama_index
transformers
torch
# external requirements
click
Sphinx
coverage
awscli
flake8
python-dotenv>=0.5.1
